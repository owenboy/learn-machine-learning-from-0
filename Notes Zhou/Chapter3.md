# 第三章 线性模型

> 这一章要用到不少基础数学知识，看之前可以先了解下：

> * 数学：微分（偏微分），指数函数，对数函数
> * 线性代数：向量，矩阵，矩阵的一些基本操作与变换（转置，逆矩阵，矩阵求导，矩阵的秩等等）
> * 概率论：后验概率
> * 数值计算：凸优化理论，梯度下降法，牛顿法

## 3.1 基本形式
公式就看书吧，简单来讲就是对各个属性加权求和，还有个常数项。


## 3.2 线性回归

#### 一元线性回归 —— 单变量（单属性）
基于均方误差最小化来进行模型求解的方法称为 **[最小二乘法（Least Squares）](https://en.wikipedia.org/wiki/Least_squares)**。

从几何角度来讲，线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小。

均方差分别是w和b二次函数，求导取0必然是其极值点，可得最优解得闭式解。

#### 多元线性回归 —— 多变量（多属性）
同样可使用最小二乘法进行参数估计。这里就要用到矩阵运算了，而且要了解几个概念：

> * 满秩矩阵：用初等行变换将矩阵化为阶梯型矩阵，非零行个数为矩阵的秩，若秩与矩阵行数相等，则为行满秩矩阵
> * 正定矩阵：
> * 正则化：

如果令模型预测值逼近y的衍生物（比如对数），就会得到广义线性模型（Generalized Linear Model）。其中的衍生关系也称为联系函数（Link Function）

## 3.3 对数几率回归（逻辑回归）

对于二分类任务，理想的函数形式为阶跃函数，但是阶跃函数不连续，在0处不可导。

阶跃函数的替代函数，对数几率函数（Logistic Function），单调可微。使用对数几率函数的反函数作为联系函数，得到对数几率回归模型。

接下来做了个假设，“将y视为样本x作为正例的可能性，则1-y是其反例的可能性”。然后就引入了概率论的东西

> 后验概率：我理解的就是条件概率（学概率论的时候，只有条件概率，并没有先验后验的概念）

然后用 **[极大似然估计（Maximum Likelihood Estimation）](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)**做参数估计。会用到 **梯度下降法** 和 **牛顿法** 用来求解最优化问题。

## 3.4 线性判别分析

> * 均值向量
> * 协方差矩阵
> * 拉格朗日乘子

## 3.5 多分类学习

